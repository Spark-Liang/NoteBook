### 安装配置

- 安装

- 其他辅助工具安装
  
  - kubectx
  
  - 

- 配置
  
  - 网络环境配置

- 高可用安装

#### 安装

##### 安装配置依赖环境

1. 配置网卡设置为固定ip，配置文件为`/etc/sysconfig/network-scripts/ifcfg-<网卡名>`
   
   1. 修改配置项`BOOTPROTO`为`static`，表示使用静态ip
   
   2. IPADDR，配置为本机的固定ip
   
   3. NETMASK，网段的网络掩码一般是`255.255.255.0`
   
   4. GATEWAY，网关地址
   
   5. DNS1，dns服务器地址，常用是`223.5.5.5`

2. 配置yum为阿里源

3. 关闭swap空间
   
   ```bash
   swapoff -a 
   ```
   
   编辑`/etc/fstab` 注释掉类型为swap的分区

4. 关闭selinux和防火墙
   
   - `setenforce 0`：临时修改selinux
   
   - 修改`/etc/selinux/config`中的`SELINUX`为`disable`
   
   - 停止防火墙
     
     ```bash
     systemctl disable firewalld
     systemctl stop firewalld
     ```
   
   - 

5. 配置启动网桥和ip转发，在配置文件`/etc/sysctl.conf`添加以下内容，然后使用`sysctl -p`生效配置
   
   ```bash
   net.bridge.bridge-nf-call-ip6tables = 1
   net.bridge.bridge-nf-call-iptables = 1
   net.ipv4.ip_forward = 1
   ```
   
   使用命令`modprobe br_netfilter`先加载依赖的内核模块，然后使用`sysctl -p`加载内核配置。

6. 安装常用包
   
   ```bash
   yum install vim bash-completion net-tools gcc -y
   ```

7. 安装docker，并配置镜像加速
   
   k8s版本与docker版本对应关系，参考k8s的change log。[kubernetes/CHANGELOG at master · kubernetes/kubernetes · GitHub](https://github.com/kubernetes/kubernetes/tree/master/CHANGELOG)
   
   使用阿里云源安装docker-ce
   
   ```bash
   yum install -y yum-utils device-mapper-persistent-data lvm2
   yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
   yum -y install docker-ce
   ```

##### 安装配置k8s环境

1. 添加k8s阿里云源

```bash
cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF
```

2. 安装k8s相关工具`kubectl kubelet kubeadm`，需要注意三个工具的版本必须相同
   
   ```bash
   K8S_VERSION=1.18.20
   yum install kubectl-${K8S_VERSION} kubelet-${K8S_VERSION} kubeadm-${K8S_VERSION} -y
   ```
   
   可以通过 `yum list installed  | grep kube` 查看现在安装的kubeadm版本

3. 检查k8s依赖的docker镜像，并拉取缺少的镜像
   
   通过命令`kubeadm config images list`获取镜像列表，并将列表中的`k8s.gcr.io`替换为`registry.cn-hangzhou.aliyuncs.com/google_containers`，从而使用阿里云的仓库拉取

4. 使用`kubeadm init`初始化k8s集群

```bash
kubeadm init --kubernetes-version=1.18.0  \
--apiserver-advertise-address=192.168.122.21   \
--image-repository registry.aliyuncs.com/google_containers  \
--service-cidr=10.10.0.0/16 --pod-network-cidr=10.122.0.0/16
```

常用选项：

- `--kubernetes-version`: 对应安装时的`K8S_VERSION`
- `--apiserver-advertise-address`: 对应当前master主机的ip
- `--image-repository`:初始化时使用的镜像仓库
- `--service-dns-domain`: 集群的service dns 结尾
- `--ignore-preflight-errors`:忽略初始化时的某些报错，常见忽略Swap报错
  - `--ignore-preflight-errors=Swap`

常见错误：

- kubelet isn't running or healty
  原因是kubelet没有启动正常，需要检查 `/var/log/messages` 查看原因
- 

常见配置：

- 启动swap运行k8s
  需要配置文件`/etc/sysconfg/kubelet`中的`KUBELET_EXTRA_ARGS=` 后面添加`--fail-swap-on=false`避免启动kubelet报错

- 配置docker的`cgroupdriver`为`systemd`
  
  在`/etc/docker/daemon.json`中添加配置项
  
  ```json
  { "exec-opts": ["native.cgroupdriver=systemd"]
  }
  ```
  
  并使用`systemctl daemon-reload`和`systemctl restart docker`是配置生效

- 配置kubelet使用`cgroupfc`，需要在`/etc/sysconfig/kubelet`添加选项`--cgroup-driver=cgroupfs`
5. 当初始化完成后，使用`kubectl get pods`会发现`coredns`的pod处于pending状态。是因为缺少网络引擎，安装`calico`网络。
   
   - 安装 `calico` 网络
     
     ```bash
     wget  https://docs.projectcalico.org/manifests/calico.yaml -O /etc/kubernetes/manifests/calico.yaml --no-check-certificate
     kubectl apply -f /etc/kubernetes/manifests/calico.yaml
     ```
   
   - 安装 `flannel` 网络
     从[kube-flannel](https://github.com/flannel-io/flannel/blob/master/Documentation/kube-flannel.yml)下载k8s配置文件，然后安装到集群中
     
     ```bash
     kubectl apply -f kube-flannel.yml
     ```

6. ###### 其他节点加入

使用`kubeadm join`可以使其他节点加入初始化好的主节点，在集群初始化完成后，会给出其他节点加入的命令如：

```bash
kubeadm join 192.168.188.129:6443 --token 57816t.o0gzqldg8jyt4wqc \
    --discovery-token-ca-cert-hash sha256:e312deae635734e69e9f49b59f13f56429e52ee030ccbf8515c52fc79ec62a38
```

运行完后，需要拷贝主节点的`$HOME/.kube/config`文件到新节点上。

**同时还能通过命令`kubeadm token create --print-join-command`查看加入命令**

4. ###### 参考文档
- [使用kubeadm在Centos8上部署kubernetes1.18_Kubernetes中文社区](https://www.kubernetes.org.cn/7189.html)

#### 其他辅助工具安装

##### kubens

kubens可用于切换当前用户的默认namespace。

安装命令

```bash
git clone https://github.com/ahmetb/kubectx
cp kubectx/kube* /usr/local/bin/
```

#### 配置

##### 网络环境配置

###### 添加路由指向集群节点

当需要直接通过集群内部ip访问服务时，需要添加指向`--service-cidr`所配置的网段的路由。如果需要直接访问pod，则需要添加指向`--pod-network-cidr`对应网段的路由。

windows配置：

```batch
:: 添加路由
route -p add 10.10.0.0 mask 255.255.0.0 192.168.188.129
:: 删除路由
route -p delete 10.10.0.0 mask 255.255.0.0 192.168.188.129
```

其中`-p` 选项代表永久添加路由

linux:

```bash
# 添加路由
route add -net 10.10.0.0 netmask 255.255.0.0 gw 192.168.188.129
# 删除路由
route del -net 10.10.0.0 netmask 255.255.0.0 gw 192.168.188.129
```

 **注意点：每个节点必须包含指向所有pod和service endpoint的路由，比如calico网络需要配置成BGP模式。**

##### 配置查看

api-server相关配置可以查询运行在`kube-system`下的`api-server`的pod。

#### 高可用安装

##### 依赖软件

- ntp: 时间同步

- mail：发送监控邮件，通过`yum install -y mailx sendmail`安装

- killall: 通过`yum install psmisc -y`安装

- keepalived：用于将多个节点的正常服务映射到一个虚拟ip进行访问，当某个节点的服务不正常时，通过路由器将虚拟ip指向正常节点上。

- haproxy：支持4层和7层协议的负载均衡

##### 依赖环境

在非HA环境下，增加以下环境依赖项

- 内核参数：
  
  - `net.ipv4.ip_nonlocal_bind = 1`

- 各节点安装ipset服务
  
  ```bash
  # 安装ipvs
  yum -y install ipvsadm ipset sysstat conntrack libseccomp
  # 启动对应的内核模块
  modprobe -- ip_vs
  modprobe -- ip_vs_rr
  modprobe -- ip_vs_wrr
  modprobe -- ip_vs_sh
  modprobe -- nf_conntrac
  
  # 检查是否启动成功
  grep -e ip_vs -e nf_conntrack_ipv4
  ```

##### 高可用相关配置

配置项要点：

- 使用keepalived配置非抢占式主备切换，保证apiservice 高可用

- 使用haproxy对apiservice进行负载均衡

配置步骤

1. 安装keepalived和haproxy
   
   ```bash
   yum -y install haproxy keepalived
   ```

2. 配置keepalived配置文件`/etc/keepalived/keepalived.conf`，由于是非抢占式，所以所有节点的配置文件均相同
   
   ```bash
   global_defs {
      router_id LVS_DEVEL
   
      # 添加如下内容
      script_user root
      enable_script_security
   }
   
   # 配置服务检查脚本
   vrrp_script check_haproxy {
       script "/etc/keepalived/check_haproxy.sh"         # 检测脚本路径
       interval 3
       weight -2 
       fall 10
       rise 2
   }
   
   # 添加网关连通性检查，避免网络导致脑裂
   vrrp_script check_gateway {
       script "/etc/keepalived/check_gateway.sh"         # 检测脚本路径
       interval 10
       weight -2 
       fall 3
       rise 2
   }
   
   vrrp_instance VI_1 {
       state BACKUP            # 非抢占式，所有节点均为BACKUP
       interface ens32         # 本机网卡名
       virtual_router_id 51
       priority 100             # 权重100
       advert_int 1
       authentication {
           auth_type PASS
           auth_pass 1111
       }
       virtual_ipaddress {
           192.168.188.70      # 虚拟IP
       }
       track_script {
           check_gateway
           check_haproxy       # 模块
       }
   }
   ```
   
   配置文件使用的脚本文件参考[check_gateway.sh](ref/check_gateway.sh) 和 [check_haproxy.sh](ref/check_haproxy.sh)

3. 配置haproxy配置文件`/etc/haproxy/haproxy.cfg`，文件内容如下。通常只需要修改backend 对应的服务器地址
   
   ```
   #---------------------------------------------------------------------
   # Example configuration for a possible web application.  See the
   # full configuration options online.
   #
   #   http://haproxy.1wt.eu/download/1.4/doc/configuration.txt
   #
   #---------------------------------------------------------------------
   
   #---------------------------------------------------------------------
   # Global settings
   #---------------------------------------------------------------------
   global
       # to have these messages end up in /var/log/haproxy.log you will
       # need to:
       #
       # 1) configure syslog to accept network log events.  This is done
       #    by adding the '-r' option to the SYSLOGD_OPTIONS in
       #    /etc/sysconfig/syslog
       #
       # 2) configure local2 events to go to the /var/log/haproxy.log
       #   file. A line like the following can be added to
       #   /etc/sysconfig/syslog
       #
       #    local2.*                       /var/log/haproxy.log
       #
       log         127.0.0.1 local2
   
       chroot      /var/lib/haproxy
       pidfile     /var/run/haproxy.pid
       maxconn     4000
       user        haproxy
       group       haproxy
       daemon
   
       # turn on stats unix socket
       stats socket /var/lib/haproxy/stats
   
   #---------------------------------------------------------------------
   # common defaults that all the 'listen' and 'backend' sections will
   # use if not designated in their block
   #---------------------------------------------------------------------
   defaults
       mode                    http
       log                     global
       option                  httplog
       option                  dontlognull
       option http-server-close
       option forwardfor       except 127.0.0.0/8
       option                  redispatch
       retries                 3
       timeout http-request    10s
       timeout queue           1m
       timeout connect         10s
       timeout client          1m
       timeout server          1m
       timeout http-keep-alive 10s
       timeout check           10s
       maxconn                 3000
   
   #---------------------------------------------------------------------
   # main frontend which proxys to the backends
   #---------------------------------------------------------------------
   frontend  kubernetes-apiserver
       mode                        tcp
       bind                        *:16443
       option                      tcplog
       default_backend             kubernetes-apiserver
   
   #---------------------------------------------------------------------
   # static backend for serving up images, stylesheets and such
   #---------------------------------------------------------------------
   listen stats
       bind            *:1080
       stats auth      admin:admin
       stats refresh   5s
       stats realm     HAProxy\ Statistics
       stats uri       /admin?stats
   
   #---------------------------------------------------------------------
   # round robin balancing between the various backends
   #---------------------------------------------------------------------
   backend kubernetes-apiserver
       mode        tcp
       balance     roundrobin
       server  k8s-master-001 k8s-master-001.spark-liang:6443 check
       server  k8s-master-002 k8s-master-002.spark-liang:6443 check
       server  k8s-master-003 k8s-master-003.spark-liang:6443 check
   ```

4. 启动keepalived和haproxy服务并加入开机启动
   
   ```bash
   systemctl start keepalived && systemctl enable keepalived
   systemctl start haproxy && systemctl enable haproxy
   ```

5. 获取集群默认配置，并修改ip、主机名、虚拟ip和haproxy端口，配置使用ipvs代理
   
   ```bash
   kubeadm config print init-defaults > kubeadm-config.yaml
   ```
   
   实例配置文件，注释地方需要重点替换：
   
   ```
   apiVersion: kubeadm.k8s.io/v1beta2
   bootstrapTokens:
   - groups:
     - system:bootstrappers:kubeadm:default-node-token
     token: abcdef.0123456789abcdef
     ttl: 24h0m0s
     usages:
     - signing
     - authentication
   kind: InitConfiguration
   localAPIEndpoint:
     advertiseAddress: 192.168.200.3     # 本机IP
     bindPort: 6443
   nodeRegistration:
     criSocket: /var/run/dockershim.sock
     name: master1        # 本主机名
     taints:
     - effect: NoSchedule
       key: node-role.kubernetes.io/master
   ---
   apiServer:
     timeoutForControlPlane: 4m0s
   apiVersion: kubeadm.k8s.io/v1beta2
   certificatesDir: /etc/kubernetes/pki # ca证书和各个api
   clusterName: kubernetes
   controlPlaneEndpoint: "192.168.200.16:16443"    # 虚拟IP和haproxy端口
   controllerManager: {}
   dns:
     type: CoreDNS
   etcd:
     local:
       dataDir: /var/lib/etcd
   imageRepository: registry.aliyuncs.com/google_containers    # 镜像仓库源要根据自己实际情况修改
   kind: ClusterConfiguration
   kubernetesVersion: v1.18.2     # k8s版本
   networking:
     dnsDomain: cluster.local
     podSubnet: "10.244.0.0/16"
     serviceSubnet: 10.96.0.0/12
   scheduler: {}
   
   ---
   apiVersion: kubeproxy.config.k8s.io/v1alpha1
   kind: KubeProxyConfiguration
   featureGates:
     SupportIPVSProxyMode: true
   mode: ipvs
   ```

```
6. 初始化集群

```bash
kubeadm config images pull --config kubeadm-config.yaml
```

7. 拷贝部分生成的etcd证书、proxy证书和ca证书，还有admin.conf到各个master节点
   
   ```bash
   TARGET_HOST=192.168.188.72
   scp /etc/kubernetes/pki/ca.* root@${TARGET_HOST}:/etc/kubernetes/pki/
   scp /etc/kubernetes/pki/sa.* root@${TARGET_HOST}:/etc/kubernetes/pki/
   scp /etc/kubernetes/pki/front-proxy-ca.* root@${TARGET_HOST}:/etc/kubernetes/pki/
   scp /etc/kubernetes/pki/etcd/ca.* root@${TARGET_HOST}:/etc/kubernetes/pki/etcd/
   scp /etc/kubernetes/admin.conf root@${TARGET_HOST}:/etc/kubernetes/
   ```

8. 其他节点加入集群
   
   其中加入命令可以通过`kubeadm token create --print-join-command`查看，master加入时需要加上`--control-plane`选项。
   
   ```bash
   # master
   kubeadm join 192.168.200.16:16443 --token abcdef.0123456789abcdef \
       --discovery-token-ca-cert-hash sha256:f0489748e3b77a9a29443dae2c4c0dfe6ff4bde0daf3ca8740dd9ab6a9693a78 \
       --control-plane
   # node
   kubeadm join 192.168.200.16:16443 --token abcdef.0123456789abcdef \
       --discovery-token-ca-cert-hash sha256:f0489748e3b77a9a29443dae2c4c0dfe6ff4bde0daf3ca8740dd9ab6a9693a78 \
   ```

9. 

参考教程：[kubeadm部署k8s高可用集群 - 行走的RMB - 博客园](https://www.cnblogs.com/lfl17718347843/p/13417304.html)

#### 其他参考文档

- [kubeadm Configuration (v1beta2) | Kubernetes](https://kubernetes.io/docs/reference/config-api/kubeadm-config.v1beta2/)

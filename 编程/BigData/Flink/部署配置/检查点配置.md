# 检查点配置

[TOC]

## 基础环境要求

### Standalone集群

约束条件：

- flink standalone只能使用集群启动时已经支持的文件系统做checkpoint存储，不能使用运行时用户传递的jar包提供的文件系统实现。
- 如果需要使用hadoop相关的文件系统，必须保证hadoop相关的jar包在启动的classpath中。具体的逻辑可以看`org.apache.flink.core.fs.FileSystem`的`loadHadoopFsFactory`方法。

环境配置步骤：

1. 确保flink启动时设置了 HADOOP_CONF_DIR 变量以及 HADOOP_CLASSPATH 变量。
   - 可以通过全局环境变量设置 HADOOP_CONF_DIR 和 HADOOP_CLASSPATH
   - 也可以通过修改 `$FLINK_HOME/bin/config.sh` 在里面添加 HADOOP_CONF_DIR 和 HADOOP_CLASSPATH 的配置
2. 

### On Yarn

### On K8s



## 常用配置示例

### 文件系统

```yaml
# 用于存储和检查点状态
# state.backend: filesystem
# 存储检查点的数据文件和元数据的默认目录
# state.checkpoints.dir: hdfs://namenode-host:port/flink-checkpoints
# savepoints 的默认目标目录(可选)
# state.savepoints.dir: hdfs://namenode-host:port/flink-checkpoints
# 用于启用/禁用增量 checkpoints 的标志
# state.backend.incremental: false
```





## 相关文档

- 
- [何时以及如何在 Apache Flink 中使用 RocksDB 状态后端](https://blog.csdn.net/u010942041/article/details/114944767)
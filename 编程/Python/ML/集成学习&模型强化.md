#### 集成学习

集成学习的主要思路是通过训练多个模型，然后进行投票，票数高的即为预测结果。**集成学习最重要的是尽量训练出差异大的模型。**集成学习相对而言对差异性的要求，比对单个模型的准确度要求更高。原因如下：<br>

假设每个子模型准确率为51%:

- 当只有一个子模型，模型的整体准确度为51%。

- 当只有3个子模型，模型的整体准确度为$0.51^3+C_3^2\cdot0.51^2\cdot0.49+C_3^1\cdot0.51\cdot0.49^2=51.5%$。

- 当只有500个子模型，模型的整体准确度为65.6%。

假设每个子模型准确率为60%:

- 当我们有500个模型，模型的整体准确率为 99.999%



##### hard vote 和 soft vote

- hard vote: 直接按照票数进行投票

- soft vote：按照每个分类预测的概率为权重，权重最高的分类为预测类型
  
  - 使用soft vote 要求必须每个模型都能计算概率。



##### bagging， pasting 和 oob

- bagging 表示有放回的抽取

- pasting 表示无放回地抽取
  
  - 缺点：在同样样本数量的情况下，模型训练的数量更少。

**对于bagging，会有约37%没有被抽取到进行训练，这些样本就被称为 "oob"(Out-of-bag)。这些样本可以用来进行模型的准确性的评分。**在scikit-learn中提供了 oob\_score\_ 的方法直接调用。



##### random subspaces 和 random patches

- random subspaces：对特征进行随机采用，然后采用全量的样本进行训练

- random patches：同时针对样本和特征进行随机取样。



##### scikit-learn中使用集成学习

###### 使用 VotingClassifier

scikit-learn把 VotingClassifier 封装在了 sklearn.ensemble 模块中。其用法如下:

```python
from sklearn.ensemble import VotingClassifier

clf = VotingClassifier(estimators=[
    ('log_clf',LogisticRegression()),
    ('svm_clf',SVC(probability=True)), # 要使得SVM支持计算概率，必须添加probability
    ('dt_clf',DecisionTreeClassifier())
],voting='soft')

clf.fit(X_train,y_train)
```



###### 使用BaggingClassifier

在scikit-learn中只有 BaggingClassifier类而没有 PastingClassifier类，而是采用参数 bootstrap 参数来控制。当 bootstrap为 True 即采用 Bagging ， 为 False 则采用 Pasting。默认为 True<br>

BaggingClassifier是通过分割训练数据集来达到获得多个模型的目的，而VotingClassifier则是直接通过传入多个模型实例来达到多个模型投票的目的。

```python
from sklearn.ensemble import BaggingClassifier

clf = BaggingClassifier(DecisionTreeClassifier(), # base classifier
    n_estimators=500, max_samples=100 ,
    bootstrap=True, oob_score=True
)

clf.fit(X,y) # 直接采用原数据集进行训练，因为可以采用 oob_score 的方式计算准确度
clf.oob_score_

# ramdom subspace
clf = BaggingClassifier(DecisionTreeClassifier(), # base classifier
     n_estimators=500, max_features=100, bootstrap_features=True
     bootstrap=True, oob_score=True
)

# ramdom subspaces
clf = BaggingClassifier(DecisionTreeClassifier(), # base classifier
 n_estimators=500, 
 max_samples=100 ,bootstrap=True,
 max_features=100, bootstrap_features=True
 bootstrap=True, oob_score=True
)

# 对于 max_samples, max_features 当传入 int 表示sample 的数量，当传入float时表示抽取的比例。默认都是 1.0
```







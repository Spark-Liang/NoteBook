#### LinerRegression

线性回归模型在假设各个参数对预测的都存在线性关系的前提下，计算各个特征在线性模型中的系数，该系数就表示特征对目标值的影响因数。

##### 线性回归模型的思想

- 首先确定模型的目标为，求出模型参数向量θ，使得所有点的预测值和真实值总误差最小

- 确定衡量总误差的标准：$\sum_{i=1}^{m}(\hat y-y^{(i)})^2$，其中在线性回归中 $y^{(i)}=X^{(i)} \cdot θ, 其中 X^{(0)}=1$

- 求误差函数的最小值 → 误差函数导数为0

该思想可以推广到其他的回归模型中：

- 确立模型目标

- 根据目标确定相应的损失函数或者获益函数。

- 通过求解损失函数和获益函数的极值来求解模型



##### 特点：

- 采用线性回归模型直接求解模型 不需要进行归一化也能准确地计算出模型参数。但是采用梯度下降法计算模型参数时，需要对特征进行归一化。

- 优点：
  
  - 模型的可解释性强



##### 衡量线性回归准确性的标准

- MSE，RMSE：均方误差或者均方根误差

- MAE：平均绝对误差: $\sum_{i=1}^{m}|\hat y-y^{(i)}|$

- $R^2$标准，其中 $R^2=\cfrac{\sum_{i=1}^{m}(\hat y-y^{(i)})^2}{\sum_{i=1}^{m}(\bar y-y^{(i)})^2}=1-\cfrac{MSE}{Var(y)}$ ，其中分母$\sum_{i=1}^{m}(\bar y-y^{(i)})^2$实际可以理解成一个基本模型，即使用均值预测所有的值，相当于一个没有做任何事情的线性模型。当$R^2=1$相当于完全准确，当$$R^2=0$相当于完全不准确，当$R^2 \lt 0$ 相当于特征与实际值没有线性关系。






